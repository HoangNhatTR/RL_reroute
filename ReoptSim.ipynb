{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyO1SCSVUI2p+f3ruG11FC0Y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install pulp"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ebL_Q6UPbE5J","executionInfo":{"status":"ok","timestamp":1767667942800,"user_tz":-420,"elapsed":9831,"user":{"displayName":"Hoàng Nhật","userId":"05017303340377483025"}},"outputId":"26aa4e0d-8fb1-4c96-a2bb-d7290385dd9d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pulp in /usr/local/lib/python3.12/dist-packages (3.3.0)\n"]}]},{"cell_type":"code","source":["import networkx as nx\n","import random\n","import pulp\n","from scipy.special import gamma\n","from itertools import islice\n","\n","# --- CẤU HÌNH ---\n","NUM_NODES = 32\n","NUM_LINKS = 250\n","LINK_CAPACITY = 300\n","TARGET_CONNECTIONS = 1000\n","WEIBULL_SHAPE = 0.8\n","MEAN_BANDWIDTH = 50\n","WEIBULL_SCALE = MEAN_BANDWIDTH / gamma(1 + 1/WEIBULL_SHAPE)\n","\n","# --- CÁC HÀM CƠ BẢN (GIỮ NGUYÊN) ---\n","def generate_network_topology(num_nodes, num_links):\n","    while True:\n","        G = nx.gnm_random_graph(num_nodes, num_links, directed=True)\n","        if nx.is_weakly_connected(G): break\n","    for u, v in G.edges():\n","        G[u][v]['capacity'] = LINK_CAPACITY\n","        G[u][v]['residual_capacity'] = LINK_CAPACITY\n","    return G\n","\n","def get_weibull_bandwidth():\n","    return max(1.0, random.weibullvariate(WEIBULL_SCALE, WEIBULL_SHAPE))\n","\n","def find_path_sufficient_bandwidth(G, source, target, bandwidth):\n","    try:\n","        shortest_paths = nx.shortest_simple_paths(G, source, target)\n","        for path in islice(shortest_paths, 10):\n","            is_feasible = True\n","            for i in range(len(path) - 1):\n","                u, v = path[i], path[i+1]\n","                if G[u][v]['residual_capacity'] < bandwidth:\n","                    is_feasible = False; break\n","            if is_feasible: return path\n","    except: return None\n","    return None\n","\n","def simulate_traffic_loading(G, target_count):\n","    connections = []\n","    request_id = 0\n","    failures = 0\n","    print(f\"1. Đang nạp traffic (Mục tiêu: {target_count})...\")\n","    while len(connections) < target_count and failures < 200:\n","        src = random.randint(0, NUM_NODES - 1)\n","        dst = random.randint(0, NUM_NODES - 1)\n","        while src == dst: dst = random.randint(0, NUM_NODES - 1)\n","        bw = get_weibull_bandwidth()\n","        path = find_path_sufficient_bandwidth(G, src, dst, bw)\n","        if path:\n","            for i in range(len(path) - 1): G[path[i]][path[i+1]]['residual_capacity'] -= bw\n","            shortest_ideal = nx.shortest_path(G, src, dst)\n","            connections.append({\n","                'request_id': request_id, 'source': src, 'target': dst,\n","                'bandwidth': round(bw, 2), 'current_path': path,\n","                'path_length': len(path) - 1,\n","                'is_shortest_path': (len(path) == len(shortest_ideal))\n","            })\n","            request_id += 1; failures = 0\n","        else: failures += 1\n","    return connections\n","\n","# --- BƯỚC MỚI: TẠO KHOẢNG TRỐNG ---\n","def simulate_network_churn(G, traffic_requests, removal_rate=0.1):\n","    print(f\"\\n2. Đang giải phóng {removal_rate*100}% kết nối để tạo khoảng trống...\")\n","\n","    # Chọn ngẫu nhiên các kết nối để xóa\n","    num_to_remove = int(len(traffic_requests) * removal_rate)\n","    removed_indices = random.sample(range(len(traffic_requests)), num_to_remove)\n","\n","    # Cập nhật lại dung lượng mạng (trả lại băng thông)\n","    remaining_traffic = []\n","    for i, req in enumerate(traffic_requests):\n","        if i in removed_indices:\n","            # Trả lại băng thông cho mạng\n","            path = req['current_path']\n","            bw = req['bandwidth']\n","            for j in range(len(path) - 1):\n","                u, v = path[j], path[j+1]\n","                G[u][v]['residual_capacity'] += bw\n","        else:\n","            remaining_traffic.append(req)\n","\n","    print(f\"-> Đã xóa {num_to_remove} kết nối. Mạng lưới giờ đã thoáng hơn!\")\n","\n","    # Cập nhật lại trạng thái is_shortest_path cho các kết nối còn lại\n","    # (Vì mạng thoáng hơn, đường ngắn nhất cũ có thể đã khả dụng, nhưng ở đây ta giữ nguyên\n","    # trạng thái cũ để xem thuật toán tối ưu có tự tìm ra không)\n","    return remaining_traffic\n","\n","# --- REOPT_SIM ---\n","def run_reopt_sim(G, traffic_requests, max_reroutes_T=50):\n","    print(f\"\\n3. --- CHẠY AGENT RL (|T| = {max_reroutes_T}) ---\")\n","\n","    # Chỉ tối ưu những thằng đang đi đường dài\n","    candidates = [r for r in traffic_requests if not r['is_shortest_path']]\n","    print(f\"Số kết nối cần tối ưu (candidates): {len(candidates)}\")\n","\n","    if len(candidates) == 0: return\n","\n","    link_capacity = {(u, v): G[u][v]['capacity'] for u, v in G.edges()}\n","    request_options = {}\n","\n","    for req in traffic_requests:\n","        rid = req['request_id']\n","        src, dst = req['source'], req['target']\n","        current_path = req['current_path']\n","        opts = [{'path': current_path, 'cost': len(current_path)-1, 'is_new': False}]\n","\n","        # Luôn thử tìm đường ngắn nhất hiện tại (giờ đã có thể đi được do bước Churn)\n","        try:\n","            shortest_path = nx.shortest_path(G, src, dst)\n","            # Nếu đường ngắn nhất thực sự ngắn hơn đường đang đi\n","            if len(shortest_path) < len(current_path):\n","                opts.append({'path': shortest_path, 'cost': len(shortest_path)-1, 'is_new': True})\n","        except: pass\n","        request_options[rid] = opts\n","\n","    prob = pulp.LpProblem(\"Reopt\", pulp.LpMinimize)\n","    x = {}\n","    for rid, opts in request_options.items():\n","        for i in range(len(opts)): x[(rid, i)] = pulp.LpVariable(f\"x_{rid}_{i}\", cat='Binary')\n","\n","    # Objective\n","    total_load = 0\n","    for rid, opts in request_options.items():\n","        bw = next(r for r in traffic_requests if r[\"request_id\"] == rid)[\"bandwidth\"]\n","        for i, opt in enumerate(opts): total_load += x[(rid, i)] * bw * opt['cost']\n","    prob += total_load\n","\n","    # Constraints\n","    for rid, opts in request_options.items():\n","        prob += pulp.lpSum([x[(rid, i)] for i in range(len(opts))]) == 1\n","\n","    for u, v in G.edges():\n","        load = 0\n","        for rid, opts in request_options.items():\n","            bw = next(r for r in traffic_requests if r[\"request_id\"] == rid)[\"bandwidth\"]\n","            for i, opt in enumerate(opts):\n","                if (u, v) in zip(opt['path'], opt['path'][1:]): load += x[(rid, i)] * bw\n","        prob += load <= link_capacity[(u, v)]\n","\n","    cnt = 0\n","    for rid, opts in request_options.items():\n","        for i, opt in enumerate(opts):\n","            if opt['is_new']: cnt += x[(rid, i)]\n","    prob += cnt <= max_reroutes_T\n","\n","    print(\"Đang giải ILP...\")\n","    prob.solve(pulp.PULP_CBC_CMD(msg=0))\n","\n","    if pulp.LpStatus[prob.status] == 'Optimal':\n","        init_load = sum(r['bandwidth'] * (len(r['current_path']) - 1) for r in traffic_requests)\n","        final_load = pulp.value(prob.objective)\n","        saved = init_load - final_load\n","        rerouted = sum(1 for rid, opts in request_options.items() for i, opt in enumerate(opts) if pulp.value(x[(rid, i)])==1 and opt['is_new'])\n","        print(f\"KẾT QUẢ: Tiết kiệm {saved:.2f} băng thông.\")\n","        print(f\"Số kết nối định tuyến lại: {rerouted}\")\n","    else:\n","        print(\"Không tìm thấy giải pháp.\")\n","\n","# --- CHẠY ---\n","net = generate_network_topology(NUM_NODES, NUM_LINKS)\n","# Nạp đầy\n","full_data = simulate_traffic_loading(net, TARGET_CONNECTIONS)\n","# Xóa bớt để tạo lỗ hổng\n","churned_data = simulate_network_churn(net, full_data, removal_rate=0.1)\n","# Tối ưu\n","run_reopt_sim(net, churned_data, max_reroutes_T=50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4cp1mJnxhjvS","executionInfo":{"status":"ok","timestamp":1767667953505,"user_tz":-420,"elapsed":10707,"user":{"displayName":"Hoàng Nhật","userId":"05017303340377483025"}},"outputId":"ca60a896-a638-4174-8f8c-f62b48897a92"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1. Đang nạp traffic (Mục tiêu: 1000)...\n","\n","2. Đang giải phóng 10.0% kết nối để tạo khoảng trống...\n","-> Đã xóa 100 kết nối. Mạng lưới giờ đã thoáng hơn!\n","\n","3. --- CHẠY REOPT_SIM (|T| = 50) ---\n","Số kết nối cần tối ưu (candidates): 110\n","Đang giải ILP...\n","KẾT QUẢ: Tiết kiệm 842.09 băng thông.\n","Số kết nối định tuyến lại: 40\n"]}]},{"cell_type":"code","source":["import copy\n","\n","# --- 1. ĐỊNH NGHĨA THUẬT TOÁN CŨ (GREEDY) ---\n","def run_greedy_reopt(G_original, traffic_requests_original):\n","    print(\"\\n--- CHẠY THUẬT TOÁN CŨ (SEQUENTIAL GREEDY) ---\")\n","\n","    # Tạo bản sao dữ liệu để không ảnh hưởng đến thuật toán kia\n","    G = copy.deepcopy(G_original)\n","    traffic_requests = copy.deepcopy(traffic_requests_original)\n","\n","    candidates = [r for r in traffic_requests if not r['is_shortest_path']]\n","    print(f\"Số lượng candidate ban đầu: {len(candidates)}\")\n","\n","    rerouted_count = 0\n","    bw_saved = 0\n","    initial_load = sum(r['bandwidth'] * (len(r['current_path']) - 1) for r in traffic_requests)\n","\n","    # Duyệt qua từng candidate và xử lý ngay lập tức\n","    for req in candidates:\n","        src, dst = req['source'], req['target']\n","        bw = req['bandwidth']\n","        current_path_len = len(req['current_path']) - 1\n","\n","        try:\n","            # Tìm đường ngắn nhất hiện tại\n","            shortest_path = nx.shortest_path(G, src, dst)\n","            new_len = len(shortest_path) - 1\n","\n","            # Nếu đường mới ngắn hơn đường cũ\n","            if new_len < current_path_len:\n","                # KIỂM TRA DUNG LƯỢNG (Make-Before-Break)\n","                # Phải đảm bảo đường mới có đủ residual capacity\n","                is_feasible = True\n","                for i in range(len(shortest_path) - 1):\n","                    u, v = shortest_path[i], shortest_path[i+1]\n","                    if G[u][v]['residual_capacity'] < bw:\n","                        is_feasible = False\n","                        break\n","\n","                if is_feasible:\n","                    # THỰC HIỆN ĐỔI NGAY (Cập nhật đồ thị)\n","                    # 1. Trừ dung lượng ở đường mới\n","                    for i in range(len(shortest_path) - 1):\n","                        u, v = shortest_path[i], shortest_path[i+1]\n","                        G[u][v]['residual_capacity'] -= bw\n","\n","                    # (Lưu ý: Trong mô phỏng đơn giản này ta không cộng lại dung lượng đường cũ\n","                    # ngay lập tức để mô phỏng sự khắt khe của Make-Before-Break,\n","                    # hoặc có thể cộng lại tùy giả định. Ở đây ta giả định chiếm dụng tài nguyên mới xong mới nhả cũ)\n","\n","                    rerouted_count += 1\n","                    bw_saved += (bw * current_path_len) - (bw * new_len)\n","        except nx.NetworkXNoPath:\n","            pass\n","\n","    print(f\"KẾT QUẢ GREEDY:\")\n","    print(f\"- Số kết nối định tuyến lại: {rerouted_count}\")\n","    print(f\"- Băng thông tiết kiệm được: {bw_saved:.2f}\")\n","    return bw_saved\n","\n","# --- 2. CHẠY SO SÁNH TRÊN CÙNG DATA ---\n","\n","# BƯỚC 1: Chuẩn bị dữ liệu chung (Data gốc)\n","print(\"1. Đang chuẩn bị môi trường mạng chung...\")\n","# Tạo mạng\n","master_network = generate_network_topology(NUM_NODES, NUM_LINKS)\n","# Nạp đầy\n","master_data = simulate_traffic_loading(master_network, TARGET_CONNECTIONS)\n","# Tạo khoảng trống (Churn)\n","master_churned_data = simulate_network_churn(master_network, master_data, removal_rate=0.1)\n","\n","# BƯỚC 2: Chạy Greedy (Thuật toán cũ)\n","# Copy dữ liệu để công bằng\n","greedy_net = copy.deepcopy(master_network)\n","greedy_data = copy.deepcopy(master_churned_data)\n","saved_greedy = run_greedy_reopt(greedy_net, greedy_data)\n","\n","# BƯỚC 3: Chạy Reopt_sim (Thuật toán của bài báo)\n","# Copy lại dữ liệu gốc lần nữa\n","reopt_net = copy.deepcopy(master_network)\n","reopt_data = copy.deepcopy(master_churned_data)\n","# Chạy reopt_sim (Sử dụng hàm bạn đã có ở câu trả lời trước)\n","# Lưu ý: Hàm run_reopt_sim cần sửa lại chút để trả về giá trị 'saved' nếu muốn so sánh tự động,\n","# nhưng nhìn log in ra cũng được.\n","run_reopt_sim(reopt_net, reopt_data, max_reroutes_T=50)\n","\n","# BƯỚC 4: Nhận xét\n","print(\"\\n\" + \"=\"*40)\n","print(\"SO SÁNH KẾT QUẢ\")\n","print(f\"Thuật toán cũ (Greedy) tiết kiệm: {saved_greedy:.2f}\")\n","print(\"Thuật toán mới (Reopt_sim) tiết kiệm: (Xem kết quả ILP bên trên)\")\n","print(\"=\"*40)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BikVjQKSisYJ","executionInfo":{"status":"ok","timestamp":1767667963217,"user_tz":-420,"elapsed":9690,"user":{"displayName":"Hoàng Nhật","userId":"05017303340377483025"}},"outputId":"ae860b55-7822-4a1f-de24-f7d6df9594c8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1. Đang chuẩn bị môi trường mạng chung...\n","1. Đang nạp traffic (Mục tiêu: 1000)...\n","\n","2. Đang giải phóng 10.0% kết nối để tạo khoảng trống...\n","-> Đã xóa 100 kết nối. Mạng lưới giờ đã thoáng hơn!\n","\n","--- CHẠY THUẬT TOÁN CŨ (SEQUENTIAL GREEDY) ---\n","Số lượng candidate ban đầu: 119\n","KẾT QUẢ GREEDY:\n","- Số kết nối định tuyến lại: 31\n","- Băng thông tiết kiệm được: 360.84\n","\n","3. --- CHẠY REOPT_SIM (|T| = 50) ---\n","Số kết nối cần tối ưu (candidates): 119\n","Đang giải ILP...\n","KẾT QUẢ: Tiết kiệm 369.07 băng thông.\n","Số kết nối định tuyến lại: 32\n","\n","========================================\n","SO SÁNH KẾT QUẢ\n","Thuật toán cũ (Greedy) tiết kiệm: 360.84\n","Thuật toán mới (Reopt_sim) tiết kiệm: (Xem kết quả ILP bên trên)\n","========================================\n"]}]},{"cell_type":"code","source":["import networkx as nx\n","import numpy as np\n","import random\n","from itertools import islice\n","\n","class RLPathSelector:\n","    def __init__(self, k_paths=5):\n","        self.K = k_paths\n","        # Giả sử dùng Q-Learning đơn giản hoặc Deep Q-Network (DQN)\n","        # Ở đây minh họa logic chọn đường\n","        self.epsilon = 0.1 # Tỷ lệ khám phá\n","\n","    def get_features(self, G, path, request_bw):\n","        \"\"\"Trích xuất đặc trưng của một con đường để làm input cho RL\"\"\"\n","        path_edges = list(zip(path, path[1:]))\n","        residuals = [G[u][v]['residual_capacity'] for u, v in path_edges]\n","\n","        # Đặc trưng 1: Nút cổ chai (Bottleneck)\n","        min_res = min(residuals)\n","        # Đặc trưng 2: Tải trung bình\n","        avg_res = sum(residuals) / len(residuals)\n","        # Đặc trưng 3: Độ dài\n","        length = len(path) - 1\n","\n","        return [min_res, avg_res, length]\n","\n","    def select_path(self, G, source, target, bandwidth):\n","        \"\"\"\n","        Thay thế cho hàm find_path cũ.\n","        Bây giờ sẽ chọn 1 trong K đường tốt nhất dựa trên \"Trí tuệ\"\n","        \"\"\"\n","        # 1. Tìm K ứng viên (K-Shortest Paths)\n","        try:\n","            candidates = list(islice(nx.shortest_simple_paths(G, source, target), self.K))\n","        except:\n","            return None\n","\n","        if not candidates:\n","            return None\n","\n","        # 2. Lọc bỏ các đường không đủ băng thông ngay lập tức (Hard Constraint)\n","        valid_candidates = []\n","        for path in candidates:\n","            path_edges = list(zip(path, path[1:]))\n","            if all(G[u][v]['residual_capacity'] >= bandwidth for u, v in path_edges):\n","                valid_candidates.append(path)\n","\n","        if not valid_candidates:\n","            return None\n","\n","        # 3. RL Chọn đường (Decision Making)\n","        # Đây là chỗ RL tỏa sáng thay vì chỉ lấy valid_candidates[0]\n","\n","        # --- LOGIC RL (Mô phỏng) ---\n","        if random.random() < self.epsilon:\n","            # Khám phá: Chọn ngẫu nhiên để học cái mới\n","            selected_path = random.choice(valid_candidates)\n","        else:\n","            # Khai thác: Chọn đường có điểm số cao nhất từ Model\n","            # (Ở đây bạn sẽ gọi Model.predict(features))\n","\n","            # Ví dụ heuristic thông minh mà RL có thể học được:\n","            # \"Chọn đường có Bottleneck lớn nhất (Load Balancing)\"\n","            # thay vì đường ngắn nhất.\n","            best_score = -1\n","            selected_path = valid_candidates[0]\n","\n","            for path in valid_candidates:\n","                feats = self.get_features(G, path, bandwidth)\n","                # Giả sử Model học được trọng số: 0.7 * Bottleneck - 0.3 * Length\n","                score = 0.7 * feats[0] - 0.3 * feats[2]\n","\n","                if score > best_score:\n","                    best_score = score\n","                    selected_path = path\n","\n","        return selected_path\n","\n","# --- CÁCH SỬ DỤNG TRONG REOPT_SIM ---\n","# Khởi tạo Agent\n","rl_agent = RLPathSelector(k_paths=5)\n","\n"],"metadata":{"id":"FPrV_OTpDrRv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import networkx as nx\n","import copy\n","from itertools import islice\n","\n","# --- 1. CLASS: \"TRỢ LÝ THÔNG MINH\" (MÔ PHỎNG RL) ---\n","class SmartPathSelector:\n","    def __init__(self, k_search=10):\n","        self.K = k_search\n","\n","    def select_best_path(self, G, src, dst, required_bw):\n","        \"\"\"\n","        Thay vì chọn đường ngắn nhất một cách mù quáng,\n","        hàm này chọn đường 'Tốt nhất' trong Top-K dựa trên độ thoáng của đường.\n","        \"\"\"\n","        try:\n","            # 1. Lấy Top-K đường ngắn nhất\n","            # (RL sẽ quan sát K đường này)\n","            candidates = list(islice(nx.shortest_simple_paths(G, src, dst), self.K))\n","        except:\n","            return None\n","\n","        if not candidates:\n","            return None\n","\n","        # 2. Lọc các đường hợp lệ (Đủ băng thông)\n","        valid_paths = []\n","        for path in candidates:\n","            path_edges = list(zip(path, path[1:]))\n","            residuals = [G[u][v]['residual_capacity'] for u, v in path_edges]\n","            min_residual = min(residuals)\n","\n","            if min_residual >= required_bw:\n","                # Lưu lại đường đi và 'Điểm số' của nó\n","                # Điểm số = Dung lượng dư thừa còn lại (Càng lớn càng tốt)\n","                valid_paths.append({\n","                    'path': path,\n","                    'cost': len(path) - 1,\n","                    'score': min_residual  # Heuristic mà RL sẽ học được\n","                })\n","\n","        if not valid_paths:\n","            return None\n","\n","        # 3. Ra quyết định (Action)\n","        # Chọn đường có Score cao nhất (Thoáng nhất)\n","        # Nếu Score bằng nhau, chọn đường ngắn nhất (cost thấp nhất)\n","        best_choice = max(valid_paths, key=lambda x: (x['score'], -x['cost']))\n","\n","        return best_choice['path']\n","\n","# --- 2. HÀM REOPT MỚI TÍCH HỢP SMART SELECTOR ---\n","def run_smart_reopt_sim(G, traffic_requests, selector, max_reroutes_T=50, name=\"Smart Reopt\"):\n","    print(f\"\\n--- CHẠY {name} (|T|={max_reroutes_T}) ---\")\n","\n","    candidates = [r for r in traffic_requests if not r['is_shortest_path']]\n","    print(f\"Số candidates: {len(candidates)}\")\n","\n","    if len(candidates) == 0: return 0\n","\n","    link_capacity = {(u, v): G[u][v]['capacity'] for u, v in G.edges()}\n","    request_options = {}\n","\n","    # --- PHẦN KHÁC BIỆT CHÍNH: SINH CỘT ---\n","    for req in traffic_requests:\n","        rid = req['request_id']\n","        src, dst = req['source'], req['target']\n","        current_path = req['current_path']\n","        bw = req['bandwidth']\n","\n","        # Option 0: Đường cũ\n","        opts = [{'path': current_path, 'cost': len(current_path)-1, 'is_new': False}]\n","\n","        # Option 1: Đường Mới (Do Smart Selector chọn)\n","        if not req['is_shortest_path']:\n","            # GỌI TRỢ LÝ THÔNG MINH Ở ĐÂY\n","            smart_path = selector.select_best_path(G, src, dst, bw)\n","\n","            if smart_path:\n","                # Chỉ thêm nếu nó khác đường cũ\n","                if smart_path != current_path:\n","                    opts.append({\n","                        'path': smart_path,\n","                        'cost': len(smart_path)-1,\n","                        'is_new': True\n","                    })\n","\n","        request_options[rid] = opts\n","\n","    # --- GIẢI ILP (GIỮ NGUYÊN) ---\n","    prob = pulp.LpProblem(\"Smart_Reopt\", pulp.LpMinimize)\n","    x = {}\n","    for rid, opts in request_options.items():\n","        for i in range(len(opts)): x[(rid, i)] = pulp.LpVariable(f\"x_{rid}_{i}\", cat='Binary')\n","\n","    # Objective\n","    total_load = 0\n","    for rid, opts in request_options.items():\n","        bw = next(r for r in traffic_requests if r[\"request_id\"] == rid)[\"bandwidth\"]\n","        for i, opt in enumerate(opts): total_load += x[(rid, i)] * bw * opt['cost']\n","    prob += total_load\n","\n","    # Constraints\n","    for rid, opts in request_options.items():\n","        prob += pulp.lpSum([x[(rid, i)] for i in range(len(opts))]) == 1\n","\n","    for u, v in G.edges():\n","        load = 0\n","        for rid, opts in request_options.items():\n","            bw = next(r for r in traffic_requests if r[\"request_id\"] == rid)[\"bandwidth\"]\n","            for i, opt in enumerate(opts):\n","                if (u, v) in zip(opt['path'], opt['path'][1:]): load += x[(rid, i)] * bw\n","        prob += load <= link_capacity[(u, v)]\n","\n","    cnt = 0\n","    for rid, opts in request_options.items():\n","        for i, opt in enumerate(opts):\n","            if opt['is_new']: cnt += x[(rid, i)]\n","    prob += cnt <= max_reroutes_T\n","\n","    prob.solve(pulp.PULP_CBC_CMD(msg=0))\n","\n","    if pulp.LpStatus[prob.status] == 'Optimal':\n","        init_load = sum(r['bandwidth'] * (len(r['current_path']) - 1) for r in traffic_requests)\n","        final_load = pulp.value(prob.objective)\n","        saved = init_load - final_load\n","        rerouted = sum(1 for rid, opts in request_options.items() for i, opt in enumerate(opts) if pulp.value(x[(rid, i)])==1 and opt['is_new'])\n","        print(f\"KẾT QUẢ: Tiết kiệm {saved:.2f} băng thông.\")\n","        print(f\"Số kết nối định tuyến lại: {rerouted}\")\n","        return saved\n","    else:\n","        print(\"Không tìm thấy giải pháp.\")\n","        return 0\n","\n","# --- 3. KỊCH BẢN CHẠY THỬ NGHIỆM SO SÁNH ---\n","\n","print(\"\\n\" + \"=\"*60)\n","print(\"THỬ NGHIỆM: STANDARD REOPT vs. SMART REOPT (RL PROXY)\")\n","print(\"=\"*60)\n","\n","# BƯỚC 1: Tạo dữ liệu khó (10% Churn)\n","# Dùng lại dữ liệu master nếu có, hoặc tạo mới\n","print(\"1. Chuẩn bị dữ liệu...\")\n","net_test = generate_network_topology(32, 250)\n","data_full = simulate_traffic_loading(net_test, 600) # Load nhẹ hơn chút để dễ thấy đường khác\n","data_churn = simulate_network_churn(net_test, data_full, removal_rate=0.1)\n","\n","# BƯỚC 2: Chạy Standard Reopt (Cách cũ: Chỉ tìm Shortest Path)\n","# Để mô phỏng cách cũ, ta dùng SmartSelector nhưng K=1 (Chỉ xem xét đúng 1 đường ngắn nhất)\n","print(\"\\n>>> RUN 1: STANDARD REOPT (Chỉ chọn Shortest Path)\")\n","net_std = copy.deepcopy(net_test)\n","data_std = copy.deepcopy(data_churn)\n","# Selector 'ngu': K=1 nghĩa là chỉ nhìn thấy đường ngắn nhất, tắc là bỏ\n","std_selector = SmartPathSelector(k_search=1)\n","saved_std = run_smart_reopt_sim(net_std, data_std, std_selector, max_reroutes_T=50, name=\"Standard Reopt\")\n","\n","# BƯỚC 3: Chạy Smart Reopt (Cách mới: Chọn trong Top-10 đường tốt nhất)\n","print(\"\\n>>> RUN 2: SMART REOPT (Chọn đường thoáng nhất trong Top-10)\")\n","net_smart = copy.deepcopy(net_test)\n","data_smart = copy.deepcopy(data_churn)\n","# Selector 'thông minh': K=10, tìm đường vòng một chút nhưng thoáng\n","smart_selector = SmartPathSelector(k_search=10)\n","saved_smart = run_smart_reopt_sim(net_smart, data_smart, smart_selector, max_reroutes_T=50, name=\"Smart Reopt\")\n","\n","# BƯỚC 4: Kết luận\n","print(\"\\n\" + \"*\"*40)\n","print(f\"TỔNG KẾT:\")\n","print(f\"Standard Reopt (Shortest): {saved_std:.2f}\")\n","print(f\"Smart Reopt (RL Proxy):    {saved_smart:.2f}\")\n","if saved_smart > saved_std:\n","    diff = saved_smart - saved_std\n","    print(f\"-> Smart Reopt HIỆU QUẢ HƠN: +{diff:.2f} ({ (diff/saved_std if saved_std>0 else 100) * 100 :.1f}%)\")\n","    print(\"-> Lý do: Nó tìm được các đường thay thế (Alternative Paths) khi đường ngắn nhất bị tắc.\")\n","else:\n","    print(\"-> Hai thuật toán ngang nhau (Mạng chưa đủ phức tạp để RL phát huy).\")\n","print(\"*\"*40)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XcR5F3aCOe6k","executionInfo":{"status":"ok","timestamp":1767668151952,"user_tz":-420,"elapsed":3523,"user":{"displayName":"Hoàng Nhật","userId":"05017303340377483025"}},"outputId":"fdb1d8b1-6680-480c-ed0b-d63b73eacb5d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","THỬ NGHIỆM: STANDARD REOPT vs. SMART REOPT (RL PROXY)\n","============================================================\n","1. Chuẩn bị dữ liệu...\n","1. Đang nạp traffic (Mục tiêu: 600)...\n","\n","2. Đang giải phóng 10.0% kết nối để tạo khoảng trống...\n","-> Đã xóa 60 kết nối. Mạng lưới giờ đã thoáng hơn!\n","\n",">>> RUN 1: STANDARD REOPT (Chỉ chọn Shortest Path)\n","\n","--- CHẠY Standard Reopt (|T|=50) ---\n","Số candidates: 46\n","KẾT QUẢ: Tiết kiệm 544.68 băng thông.\n","Số kết nối định tuyến lại: 9\n","\n",">>> RUN 2: SMART REOPT (Chọn đường thoáng nhất trong Top-10)\n","\n","--- CHẠY Smart Reopt (|T|=50) ---\n","Số candidates: 46\n","KẾT QUẢ: Tiết kiệm 399.37 băng thông.\n","Số kết nối định tuyến lại: 15\n","\n","****************************************\n","TỔNG KẾT:\n","Standard Reopt (Shortest): 544.68\n","Smart Reopt (RL Proxy):    399.37\n","-> Hai thuật toán ngang nhau (Mạng chưa đủ phức tạp để RL phát huy).\n","****************************************\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import random\n","from collections import deque\n","\n","# ==========================================\n","# PHẦN 1: MÔI TRƯỜNG GIẢ LẬP (ENVIRONMENT)\n","# ==========================================\n","class NetworkEnv:\n","    def __init__(self):\n","        # Giả sử mạng có 3 đường đi (Candidates) cho một cặp nguồn-đích\n","        # Mỗi đường có dung lượng tối đa (Capacity)\n","        self.path_capacities = np.array([100.0, 100.0, 80.0])\n","        self.current_load = np.array([0.0, 0.0, 0.0]) # Load hiện tại\n","        self.num_paths = 3\n","\n","    def reset(self):\n","        \"\"\"Reset mạng về trạng thái ngẫu nhiên (để train đa dạng)\"\"\"\n","        # Random load ban đầu từ 20% đến 50%\n","        self.current_load = self.path_capacities * np.random.uniform(0.2, 0.5, size=self.num_paths)\n","        return self.get_state()\n","\n","    def get_state(self):\n","        \"\"\"State là tỷ lệ sử dụng (Utilization) của các đường\"\"\"\n","        utilization = self.current_load / self.path_capacities\n","        return utilization # Ví dụ: [0.5, 0.2, 0.8]\n","\n","    def step(self, action, demand):\n","        # 1. Kiểm tra quá tải\n","        if self.current_load[action] + demand > self.path_capacities[action]:\n","            # [SỬA 1] Giảm hình phạt xuống -10 thôi (thay vì -100)\n","            # Để agent hiểu là \"hơi sai\" chứ không phải \"chết luôn\"\n","            reward = -10\n","            done = True\n","            return self.get_state(), reward, done\n","\n","        # 2. Cập nhật load\n","        self.current_load[action] += demand\n","\n","        # 3. Tính toán load balancing\n","        utilization = self.current_load / self.path_capacities\n","        max_util = np.max(utilization)\n","        std_util = np.std(utilization) # Độ lệch chuẩn (càng nhỏ càng đều)\n","\n","        # [SỬA 2] CÔNG THỨC THƯỞNG MỚI (DỄ HỌC HƠN)\n","        # Thưởng cứng +10 điểm vì đã định tuyến thành công\n","        # Cộng thêm điểm nếu giữ mạng cân bằng (std thấp) và thoáng (max thấp)\n","        reward = 10 + (1.0 - max_util) + (1.0 - std_util)\n","\n","        done = False\n","        return self.get_state(), reward, done\n","\n","# ==========================================\n","# PHẦN 2: BỘ NÃO AI (DQN AGENT)\n","# ==========================================\n","class DQN(nn.Module):\n","    def __init__(self, input_dim, output_dim):\n","        super(DQN, self).__init__()\n","        self.fc1 = nn.Linear(input_dim, 64)\n","        self.fc2 = nn.Linear(64, 64)\n","        self.fc3 = nn.Linear(64, output_dim) # Output ra điểm số cho từng đường\n","\n","    def forward(self, x):\n","        x = torch.relu(self.fc1(x))\n","        x = torch.relu(self.fc2(x))\n","        return self.fc3(x)\n","\n","class Agent:\n","    def __init__(self, state_size, action_size):\n","        self.state_size = state_size\n","        self.action_size = action_size\n","        self.memory = deque(maxlen=2000)\n","        self.gamma = 0.95    # Discount factor\n","        self.epsilon = 1.0   # Tỷ lệ khám phá (lúc đầu khám phá 100%)\n","        self.epsilon_min = 0.01\n","        self.epsilon_decay = 0.995\n","        self.model = DQN(state_size, action_size)\n","        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n","        self.criterion = nn.MSELoss()\n","\n","    def act(self, state):\n","        # Epsilon-Greedy: Đôi khi chọn bừa để khám phá đường mới\n","        if np.random.rand() <= self.epsilon:\n","            return random.randrange(self.action_size)\n","        state_tensor = torch.FloatTensor(state).unsqueeze(0)\n","        with torch.no_grad():\n","            q_values = self.model(state_tensor)\n","        return torch.argmax(q_values).item() # Chọn hành động có điểm cao nhất\n","\n","    def remember(self, state, action, reward, next_state, done):\n","        self.memory.append((state, action, reward, next_state, done))\n","\n","    def replay(self, batch_size):\n","        if len(self.memory) < batch_size:\n","            return\n","\n","        minibatch = random.sample(self.memory, batch_size)\n","\n","        for state, action, reward, next_state, done in minibatch:\n","            target = reward\n","            if not done:\n","                next_state_tensor = torch.FloatTensor(next_state).unsqueeze(0)\n","                target = reward + self.gamma * torch.max(self.model(next_state_tensor)).item()\n","\n","            state_tensor = torch.FloatTensor(state).unsqueeze(0)\n","            target_f = self.model(state_tensor)\n","\n","            # Cập nhật giá trị Q cho hành động đã chọn\n","            target_f[0][action] = target\n","\n","            # Train model\n","            self.optimizer.zero_grad()\n","            loss = self.criterion(target_f, self.model(state_tensor))\n","            loss.backward()\n","            self.optimizer.step()\n","\n","        if self.epsilon > self.epsilon_min:\n","            self.epsilon *= self.epsilon_decay\n","\n","# ==========================================\n","# PHẦN 3: TRAINING LOOP (VÒNG LẶP HUẤN LUYỆN)\n","# ==========================================\n","env = NetworkEnv()\n","agent = Agent(state_size=3, action_size=3)\n","batch_size = 32\n","EPISODES = 500\n","\n","print(\"--- BẮT ĐẦU TRAINING ---\")\n","for e in range(EPISODES):\n","    state = env.reset()\n","    total_reward = 0\n","\n","    for time in range(20):\n","        # [SỬA 3] GIẢM DEMAND XUỐNG\n","        # Thay vì 5-15, chỉ cho demand từ 1-5 thôi.\n","        # Mục đích: Để mạng sống sót qua 20 bước, Agent mới học cách sắp xếp.\n","        demand = np.random.uniform(1, 5)\n","\n","        action = agent.act(state)\n","        next_state, reward, done = env.step(action, demand)\n","        agent.remember(state, action, reward, next_state, done)\n","        state = next_state\n","        total_reward += reward\n","\n","        if done:\n","            break\n","\n","        agent.replay(batch_size)\n","\n","    if (e+1) % 50 == 0:\n","        # Nếu Score > 200 (tức là trung bình mỗi bước > 10 điểm) -> Là đã HỌC TỐT\n","        print(f\"Episode: {e+1}/{EPISODES}, Score: {total_reward:.2f}, Epsilon: {agent.epsilon:.2f}\")\n","\n","print(\"--- TRAINING HOÀN TẤT ---\")\n","\n","# ==========================================\n","# PHẦN 4: TEST (SO SÁNH VỚI GREEDY)\n","# ==========================================\n","print(\"\\n--- TEST: RL vs GREEDY (Shortest Path) ---\")\n","\n","# Reset môi trường cho công bằng\n","env.reset()\n","test_state = env.get_state()\n","print(f\"Load ban đầu: {test_state}\")\n","demand = 20.0\n","\n","# 1. GREEDY (Giả sử đường 0 là ngắn nhất)\n","# Greedy sẽ luôn chọn đường 0 bất kể nó có đầy hay không\n","greedy_action = 0\n","print(f\"Greedy chọn đường {greedy_action} (Mặc định ngắn nhất)\")\n","\n","# 2. RL PREDICTION\n","agent.epsilon = 0 # Tắt chế độ random, dùng 100% trí tuệ đã học\n","rl_action = agent.act(test_state)\n","print(f\"RL chọn đường {rl_action}\")\n","\n","# Phân tích\n","if test_state[0] > test_state[1] and rl_action == 1:\n","    print(\"=> KẾT LUẬN: RL THÔNG MINH! Nó tránh đường 0 đang đông để sang đường 1 thoáng hơn.\")\n","elif rl_action == greedy_action:\n","    print(\"=> KẾT LUẬN: RL chọn giống Greedy (có thể do đường 0 vẫn còn tốt).\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d5UmX1_SUCrt","executionInfo":{"status":"ok","timestamp":1767670704847,"user_tz":-420,"elapsed":575297,"user":{"displayName":"Hoàng Nhật","userId":"05017303340377483025"}},"outputId":"44e069a3-b18e-4aec-d143-a84c8cd4afdd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--- BẮT ĐẦU TRAINING ---\n","Episode: 50/500, Score: 229.93, Epsilon: 0.01\n","Episode: 100/500, Score: 230.21, Epsilon: 0.01\n","Episode: 150/500, Score: 227.90, Epsilon: 0.01\n","Episode: 200/500, Score: 227.68, Epsilon: 0.01\n","Episode: 250/500, Score: 229.97, Epsilon: 0.01\n","Episode: 300/500, Score: 227.86, Epsilon: 0.01\n","Episode: 350/500, Score: 225.01, Epsilon: 0.01\n","Episode: 400/500, Score: 225.60, Epsilon: 0.01\n","Episode: 450/500, Score: 230.38, Epsilon: 0.01\n","Episode: 500/500, Score: 229.17, Epsilon: 0.01\n","--- TRAINING HOÀN TẤT ---\n","\n","--- TEST: RL vs GREEDY (Shortest Path) ---\n","Load ban đầu: [0.32749894 0.35011508 0.41509271]\n","Greedy chọn đường 0 (Mặc định ngắn nhất)\n","RL chọn đường 0\n","=> KẾT LUẬN: RL chọn giống Greedy (có thể do đường 0 vẫn còn tốt).\n"]}]},{"cell_type":"code","source":["print(\"\\n--- TEST KỊCH BẢN KHÓ: ÉP AGENT PHẢI NÉ ĐƯỜNG NGẮN ---\")\n","\n","# 1. TẠO TÌNH HUỐNG GIẢ ĐỊNH (Rigged Scenario)\n","env.reset()\n","# Cố tình set đường 0 (Shortest) bị đầy 95%\n","# Đường 1 và 2 rất thoáng (chỉ 10%)\n","# Format: [Đường 0, Đường 1, Đường 2]\n","env.current_load = np.array([95.0, 10.0, 10.0])\n","# Capacity gốc là [100, 100, 80] -> Vậy load ratio sẽ là [0.95, 0.1, 0.125]\n","\n","rigged_state = env.get_state()\n","print(f\"Trạng thái mạng: {rigged_state}\")\n","print(\"(Đường 0 [Index 0] đang bị nghẽn 95%!)\")\n","\n","demand = 10.0 # Một luồng dữ liệu lớn cần đi qua\n","\n","# 2. HÀNH VI CỦA GREEDY\n","# Greedy thì \"mù\", chỉ biết đường 0 là ngắn nhất -> Đâm đầu vào.\n","greedy_action = 0\n","print(f\"\\n>> Greedy: Chọn đường {greedy_action} (Shortest Path)\")\n","if env.current_load[greedy_action] + demand > env.path_capacities[greedy_action]:\n","    print(\"   KẾT QUẢ GREEDY: ❌ GÂY NGHẼN MẠNG! (Load vượt quá 100)\")\n","else:\n","    print(\"   KẾT QUẢ GREEDY: May mắn thoát.\")\n","\n","# 3. HÀNH VI CỦA RL\n","agent.epsilon = 0 # Tắt random\n","rl_action = agent.act(rigged_state)\n","\n","print(f\"\\n>> RL Agent: Chọn đường {rl_action}\")\n","\n","if rl_action != 0:\n","    print(\"   KẾT QUẢ RL: ✅ THÔNG MINH! Agent đã né đường 0 để chọn đường thoáng hơn.\")\n","    # Kiểm tra xem đường mới có chịu nổi không\n","    new_load = env.current_load[rl_action] + demand\n","    if new_load <= env.path_capacities[rl_action]:\n","        print(\"   -> Định tuyến thành công, mạng vẫn an toàn.\")\n","else:\n","    print(\"   KẾT QUẢ RL: ❌ Thất bại, vẫn chọn đường nghẽn (Cần train thêm).\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"epNRqx6lZduR","executionInfo":{"status":"ok","timestamp":1767670935581,"user_tz":-420,"elapsed":32,"user":{"displayName":"Hoàng Nhật","userId":"05017303340377483025"}},"outputId":"4a8444f4-e990-4487-a674-c5e9a39da684"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- TEST KỊCH BẢN KHÓ: ÉP AGENT PHẢI NÉ ĐƯỜNG NGẮN ---\n","Trạng thái mạng: [0.95  0.1   0.125]\n","(Đường 0 [Index 0] đang bị nghẽn 95%!)\n","\n",">> Greedy: Chọn đường 0 (Shortest Path)\n","   KẾT QUẢ GREEDY: ❌ GÂY NGHẼN MẠNG! (Load vượt quá 100)\n","\n",">> RL Agent: Chọn đường 1\n","   KẾT QUẢ RL: ✅ THÔNG MINH! Agent đã né đường 0 để chọn đường thoáng hơn.\n","   -> Định tuyến thành công, mạng vẫn an toàn.\n"]}]}]}