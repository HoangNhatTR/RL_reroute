{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"7Nf5mUWQ6LH-"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g31Y0m9myuB4"},"outputs":[],"source":["import os\n","import json\n","import random\n","import glob\n","from collections import deque\n","from typing import List, Tuple\n","\n","import numpy as np\n","import networkx as nx\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51,"status":"ok","timestamp":1765446284741,"user":{"displayName":"Hoàng Nhật","userId":"05017303340377483025"},"user_tz":-420},"id":"5qYxKNL3y5ut","outputId":"f19cce90-8535-4d1c-b9b9-2c162def3bca"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cpu\n"]}],"source":["DATASETS_DIR = \"datasets\"   # folder containing load_* subfolders with snapshot_*.json\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {DEVICE}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rTH288IizFL3"},"outputs":[],"source":["# RL hyperparams\n","GAMMA = 0.99\n","LR = 1e-3\n","BATCH_SIZE = 64\n","BUFFER_CAPACITY = 20000\n","EPS_START = 1.0\n","EPS_END = 0.05\n","EPS_DECAY = 0.995\n","TARGET_UPDATE_EVERY = 5   # episodes\n","MAX_EPISODES = 800\n","MAX_STEPS_PER_EP = 30\n","\n","# Environment / network params (will be overwritten by snapshot topology)\n","DEFAULT_CAPACITY = 100.0\n","CONGESTION_THRESHOLD = 0.9  # link load/capacity \u003e threshold considered congested"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9OAXl9EyzVLi"},"outputs":[],"source":["# Reward weights\n","W_DELAY = -1.0\n","W_CONGEST = -5.0\n","W_SUCCESS = +50.0\n","W_INVALID = -50.0\n","W_BW      = -2.0\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Jwg7sFEzbKB"},"outputs":[],"source":["# ---------------------------\n","# Utilities: load snapshots\n","# ---------------------------\n","def load_all_snapshots(dataset_root: str) -\u003e List[dict]:\n","    snapshots = []\n","    if not os.path.isdir(dataset_root):\n","        raise FileNotFoundError(f\"Dataset dir not found: {dataset_root}\")\n","    # find all snapshot json files under load_* directories\n","    for load_dir in sorted(glob.glob(os.path.join(dataset_root, \"load_*\"))):\n","        for f in sorted(glob.glob(os.path.join(load_dir, \"snapshot_*.json\"))):\n","            with open(f, \"r\", encoding=\"utf-8\") as fh:\n","                data = json.load(fh)\n","            # Some fields in snapshot may use string keys for edges; normalize later\n","            snapshots.append(data)\n","    if not snapshots:\n","        raise RuntimeError(\"No snapshots found in dataset path.\")\n","    return snapshots\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BZc79kWXzfHW"},"outputs":[],"source":["# ---------------------------\n","# Environment\n","# ---------------------------\n","class RerouteEnv:\n","    \"\"\"\n","    Environment that uses snapshots as starting states.\n","    Each episode handles one flow (picked from a random snapshot).\n","    Action space: choose next-hop among neighbors of current_node.\n","    State vector: [normalized link loads flattened] + [one-hot current node] + [one-hot dest node]\n","    \"\"\"\n","\n","    def __init__(self, snapshots: List[dict]):\n","        self.snapshots = snapshots\n","        # Use first snapshot to build canonical graph (node set)\n","        base = snapshots[0]\n","        self.G = self._build_graph_from_snapshot(base)\n","        self.num_nodes = self.G.number_of_nodes()\n","        self.edges_list = list(self.G.edges())\n","        self.num_links = len(self.edges_list)\n","\n","        # runtime dynamic\n","        self.link_load = {e: 0.0 for e in self.edges_list}\n","        self.current_flow = None  # dict with id, src, dst, bw, time_left\n","        self.partial_path = []\n","        self.current_node = None\n","        self.destination = None\n","        self.max_steps = MAX_STEPS_PER_EP\n","\n","    def _build_graph_from_snapshot(self, snap: dict) -\u003e nx.DiGraph:\n","        G = nx.DiGraph()\n","        # If topology stored as dict with string keys \"(u, v)\"\n","        topo = snap.get(\"topology\", None)\n","        if topo is None:\n","            # fallback: create full graph from node count if present\n","            n = len(snap.get(\"traffic_matrix\", []))\n","            G.add_nodes_from(range(n))\n","            # no edges info -\u003e create random edges (not ideal)\n","            return G\n","        # Add nodes\n","        # collect nodes from keys\n","        nodes = set()\n","        for edge_str in topo.keys():\n","            # edge_str expected like \"(u, v)\" or \"u,v\"\n","            try:\n","                if edge_str.startswith(\"(\"):\n","                    u_str, v_str = edge_str.strip(\"()\").split(\",\")\n","                else:\n","                    u_str, v_str = edge_str.split(\",\")\n","                u = int(u_str.strip())\n","                v = int(v_str.strip())\n","            except Exception:\n","                # if keys are like \"u v\" or other, try eval\n","                try:\n","                    u, v = eval(edge_str)\n","                except Exception:\n","                    continue\n","            nodes.add(u); nodes.add(v)\n","        max_node = max(nodes) if nodes else 0\n","        G.add_nodes_from(range(max_node+1))\n","        # add edges with capacity\n","        for edge_str, meta in topo.items():\n","            try:\n","                if edge_str.startswith(\"(\"):\n","                    u_str, v_str = edge_str.strip(\"()\").split(\",\")\n","                else:\n","                    u_str, v_str = edge_str.split(\",\")\n","                u = int(u_str.strip()); v = int(v_str.strip())\n","            except Exception:\n","                try:\n","                    u, v = eval(edge_str)\n","                except Exception:\n","                    continue\n","            cap = float(meta.get(\"capacity\", DEFAULT_CAPACITY))\n","            G.add_edge(u, v, capacity=cap)\n","        return G\n","\n","    def reset(self):\n","        \"\"\"\n","        Choose a random snapshot and pick a random active flow from it.\n","        Initialize graph link loads and flow parameters.\n","        Return initial state vector.\n","        \"\"\"\n","        snap = random.choice(self.snapshots)\n","        # rebuild graph for capacity in this snapshot\n","        self.G = self._build_graph_from_snapshot(snap)\n","        self.num_nodes = self.G.number_of_nodes()\n","        self.edges_list = list(self.G.edges())\n","        self.num_links = len(self.edges_list)\n","        # init link_load from snapshot if present\n","        self.link_load = {}\n","        raw_link_load = snap.get(\"link_load\", {})\n","        # raw_link_load keys might be strings\n","        for e in self.edges_list:\n","            key = str(e)\n","            # some snapshots use \"(u, v)\" keys\n","            key2 = f\"({e[0]},{e[1]})\"\n","            load_val = 0.0\n","            if key in raw_link_load:\n","                load_val = float(raw_link_load[key])\n","            elif key2 in raw_link_load:\n","                load_val = float(raw_link_load[key2])\n","            self.link_load[e] = load_val\n","\n","        # choose an active connection to reroute\n","        active_conns = snap.get(\"active_connections\", [])\n","        if not active_conns:\n","            # fallback: create synthetic flow\n","            nodes = list(self.G.nodes())\n","            src = random.choice(nodes)\n","            dst = random.choice([n for n in nodes if n != src])\n","            bw = max(1.0, np.random.rand() * 10.0)\n","            self.current_flow = {\"id\": 0, \"src\": src, \"dst\": dst, \"bw\": bw, \"time_left\": 10.0}\n","        else:\n","            # active_conns entries like dicts {\"id\":..., \"src\":..., \"dst\":..., \"bw\":...}\n","            cand = [c for c in active_conns if isinstance(c, dict)]\n","            if not cand:\n","                # if stored as tuples list, convert\n","                cand = []\n","                for item in active_conns:\n","                    try:\n","                        cid, path, bw, on_short = item\n","                        src = path[0]; dst = path[-1]\n","                        cand.append({\"id\": cid, \"src\": src, \"dst\": dst, \"bw\": bw, \"time_left\": 10.0})\n","                    except Exception:\n","                        continue\n","            self.current_flow = random.choice(cand)\n","\n","        self.partial_path = [self.current_flow[\"src\"]]\n","        self.current_node = self.current_flow[\"src\"]\n","        self.destination = self.current_flow[\"dst\"]\n","        # episode step counter\n","        self.step_count = 0\n","\n","        state = self._build_state()\n","        return state\n","\n","    def _build_state(self) -\u003e np.ndarray:\n","        \"\"\"\n","        Build state vector:\n","            - normalized link loads flattened (len = num_links)\n","            - one-hot current node (num_nodes)\n","            - one-hot destination node (num_nodes)\n","        \"\"\"\n","        # normalized loads\n","        loads = np.array([self.link_load[e] / (self.G[e[0]][e[1]][\"capacity\"] + 1e-9) for e in self.edges_list], dtype=np.float32)\n","        # clip to [0,1]\n","        loads = np.clip(loads, 0.0, 1.0)\n","        # node one-hot\n","        cur_onehot = np.zeros(self.num_nodes, dtype=np.float32)\n","        dst_onehot = np.zeros(self.num_nodes, dtype=np.float32)\n","        cur_onehot[self.current_node] = 1.0\n","        dst_onehot[self.destination] = 1.0\n","        # concatenate\n","        state = np.concatenate([loads, cur_onehot, dst_onehot]).astype(np.float32)\n","        return state\n","\n","    def action_space(self) -\u003e List[int]:\n","        \"\"\"Return list of neighbor nodes (possible next-hops) from current_node\"\"\"\n","        return list(self.G.successors(self.current_node))\n","\n","    def compute_total_bandwidth_utilization(self):\n","        \"\"\"\n","        Tính tổng băng thông sử dụng toàn mạng = Σ(load/capacity)\n","        \"\"\"\n","        total = 0.0\n","        for (u, v) in self.edges_list:\n","            load = self.link_load.get((u, v), 0.0)\n","            cap  = float(self.G[u][v].get(\"capacity\", 1e-9))\n","            total += load / cap\n","        return total\n","\n","\n","    def step(self, action_next_node: int) -\u003e Tuple[np.ndarray, float, bool, dict]:\n","        \"\"\"\n","        action_next_node: node id chosen as next hop (must be neighbor)\n","        Procedure:\n","          - append next node to partial_path\n","          - compute shortest path from that node -\u003e destination (Dijkstra)\n","          - create full_path = partial + rest[1:]\n","          - check capacity on full_path for current_flow[\"bw\"]\n","          - if ok: allocate bw on each link of full_path\n","            compute reward based on delay and congestion\n","            if reached dest -\u003e success reward and done True\n","          - if not ok: invalid action -\u003e heavy penalty and done True\n","        \"\"\"\n","        self.step_count += 1\n","        info = {}\n","        bw = float(self.current_flow.get(\"bw\", 1.0))\n","\n","        # validate action: must be neighbor\n","        if not self.G.has_edge(self.current_node, action_next_node):\n","            # invalid\n","            reward = W_INVALID\n","            done = True\n","            return self._build_state(), reward, done, {\"reason\": \"not_neighbor\"}\n","\n","        # append partial path and compute rest using shortest path\n","        self.partial_path.append(action_next_node)\n","        try:\n","            rest = nx.shortest_path(self.G, action_next_node, self.destination)\n","        except nx.NetworkXNoPath:\n","            # no path to dest from chosen next-hop\n","            reward = W_INVALID\n","            done = True\n","            return self._build_state(), reward, done, {\"reason\": \"no_path\"}\n","\n","        # build full path\n","        full_path = self.partial_path + rest[1:]\n","        # check capacities along full_path\n","        links_in_path = [(full_path[i], full_path[i+1]) for i in range(len(full_path)-1)]\n","        insufficient = False\n","        for e in links_in_path:\n","            cap = float(self.G[e[0]][e[1]][\"capacity\"])\n","            load = float(self.link_load.get(e, 0.0))\n","            if load + bw \u003e cap + 1e-9:\n","                insufficient = True\n","                break\n","\n","        if insufficient:\n","            # invalid (would exceed capacity)\n","            reward = W_INVALID\n","            done = True\n","            return self._build_state(), reward, done, {\"reason\": \"capacity\"}\n","\n","        # allocate bandwidth on links\n","        for e in links_in_path:\n","            self.link_load[e] = self.link_load.get(e, 0.0) + bw\n","\n","        # update current node to last chosen (agent moves to that next hop)\n","        self.current_node = action_next_node\n","\n","        # compute metrics (simple approximations)\n","        # delay: average normalized load across links\n","        loads = np.array([self.link_load[e] / (self.G[e[0]][e[1]][\"capacity\"] + 1e-9) for e in self.edges_list], dtype=np.float32)\n","        avg_delay = float(np.mean(loads))\n","\n","        # congestion count\n","        congest_count = int(np.sum(loads \u003e CONGESTION_THRESHOLD))\n","        total_bw_util = self.compute_total_bandwidth_utilization()\n","\n","        # reward composition\n","        reward = (\n","                      W_DELAY * avg_delay +\n","                      W_CONGEST * congest_count +\n","                      W_BW * total_bw_util\n","                  )\n","\n","        # success?\n","        if self.current_node == self.destination:\n","            reward += W_SUCCESS\n","            done = True\n","            info[\"reached\"] = True\n","        elif self.step_count \u003e= self.max_steps:\n","            done = True\n","            info[\"timeout\"] = True\n","        else:\n","            done = False\n","\n","        next_state = self._build_state()\n","        return next_state, float(reward), done, info\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K-xmKE9Kznpd"},"outputs":[],"source":["# ---------------------------\n","# Replay Buffer\n","# ---------------------------\n","class ReplayBuffer:\n","    def __init__(self, capacity=BUFFER_CAPACITY):\n","        self.buffer = deque(maxlen=capacity)\n","\n","    def add(self, s, a, r, s2, done):\n","        self.buffer.append((s, a, r, s2, done))\n","\n","    def sample(self, batch_size):\n","        batch = random.sample(self.buffer, min(len(self.buffer), batch_size))\n","        s, a, r, s2, d = zip(*batch)\n","        return np.stack(s), np.array(a), np.array(r, dtype=np.float32), np.stack(s2), np.array(d, dtype=np.float32)\n","\n","    def size(self):\n","        return len(self.buffer)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"feL-Wf_SzrC2"},"outputs":[],"source":["# ---------------------------\n","# Q-Network (MLP)\n","# ---------------------------\n","class QNet(nn.Module):\n","    def __init__(self, state_dim: int, hidden_dim: int = 256):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(state_dim, hidden_dim),\n","            nn.ReLU(),\n","            nn.Linear(hidden_dim, hidden_dim//2),\n","            nn.ReLU(),\n","            nn.Linear(hidden_dim//2, hidden_dim//4)\n","        )\n","        # final linear head produced dynamically for variable action sizes per forward via indexing\n","\n","    def forward(self, x: torch.Tensor) -\u003e torch.Tensor:\n","        return self.net(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NR6U6eqHzv8-"},"outputs":[],"source":["# ---------------------------\n","# Training helpers\n","# ---------------------------\n","def train_q_network(qnet_base: QNet, head_out_dim_func, target_base: QNet, optimizer, buffer: ReplayBuffer, batch_size=BATCH_SIZE):\n","    \"\"\"\n","    head_out_dim_func: function that, given a batch of states, returns:\n","       - q_values_batch: list of Q-values arrays per sample for all possible actions\n","         (Because actions variable per state (different neighbor counts), here we will\n","         approximate by evaluating Q-values for all neighbors via separate small heads.)\n","    In this simplified implementation, we will:\n","       - build a candidate action set per sample by retrieving neighbors of current node from env\n","       - but because env not available here, we restrict training to samples where the action index corresponds to a neighbor index\n","    For simplicity and stability: we'll approximate by training only on samples where action is mapped to an integer index and\n","    use a small head network per sample computed by a linear layer on top of base embedding.\n","    \"\"\"\n","    if buffer.size() \u003c batch_size:\n","        return\n","    s_batch, a_batch, r_batch, s2_batch, d_batch = buffer.sample(batch_size)\n","\n","    s_batch_t = torch.tensor(s_batch, dtype=torch.float32, device=DEVICE)\n","    s2_batch_t = torch.tensor(s2_batch, dtype=torch.float32, device=DEVICE)\n","    a_batch_t = torch.tensor(a_batch, dtype=torch.long, device=DEVICE)\n","    r_batch_t = torch.tensor(r_batch, dtype=torch.float32, device=DEVICE)\n","    d_batch_t = torch.tensor(d_batch, dtype=torch.float32, device=DEVICE)\n","\n","    # base embeddings\n","    emb_s = qnet_base(s_batch_t)            # (B, emb_dim)\n","    emb_s2 = target_base(s2_batch_t)        # (B, emb_dim)\n","\n","    # To map embeddings to Q-values for chosen actions, we will use a small linear head shared:\n","    # This is a simplification: we assume action index fits into a limited range.\n","    # Create head layers on the fly (small) - note: in production design, action space should be fixed or use masking + policy net.\n","    head = nn.Linear(emb_s.shape[1], 64).to(DEVICE)\n","    head2 = nn.Linear(64, 1).to(DEVICE)  # output scalar Q for each chosen action\n","    # Create optimizer for head only (training both base+head is OK but keep simple)\n","    opt = optim.Adam(list(qnet_base.parameters()) + list(head.parameters()) + list(head2.parameters()), lr=LR)\n","\n","    # compute predicted Q for chosen action\n","    q_pred = head2(torch.relu(head(emb_s))).squeeze()  # (B,)  - scalar per sample\n","    # compute target: r + gamma * max_a' Q_target(s2, a') -- approximated by using emb_s2 through same head\n","    with torch.no_grad():\n","        q_next_all = head2(torch.relu(head(emb_s2))).squeeze()\n","        q_target = r_batch_t + GAMMA * q_next_all * (1.0 - d_batch_t)\n","\n","    loss = nn.MSELoss()(q_pred, q_target)\n","    opt.zero_grad()\n","    loss.backward()\n","    opt.step()\n","    return loss.item()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"khcPa0WFzz4V"},"outputs":[],"source":["# ---------------------------\n","# Main training loop\n","# ---------------------------\n","def train():\n","    # load snapshots\n","    snapshots = load_all_snapshots(DATASETS_DIR)\n","    env = RerouteEnv(snapshots)\n","\n","    state_dim = env.num_links + env.num_nodes * 2\n","    qnet_base = QNet(state_dim).to(DEVICE)\n","    target_base = QNet(state_dim).to(DEVICE)\n","    target_base.load_state_dict(qnet_base.state_dict())\n","\n","    buffer = ReplayBuffer()\n","    optimizer = optim.Adam(qnet_base.parameters(), lr=LR)\n","\n","    epsilon = EPS_START\n","\n","    for ep in range(1, MAX_EPISODES + 1):\n","        state = env.reset()\n","        ep_reward = 0.0\n","\n","        for step in range(MAX_STEPS_PER_EP):\n","            # get neighbor list\n","            neighbors = env.action_space()\n","            if not neighbors:\n","                # no outgoing edges -\u003e done\n","                break\n","\n","            # epsilon-greedy over neighbors\n","            if random.random() \u003c epsilon:\n","                # choose random neighbor\n","                chosen = random.choice(neighbors)\n","            else:\n","                # Evaluate q for each possible neighbor by forward through qnet_base + small head\n","                s_t = torch.tensor(state, dtype=torch.float32, device=DEVICE).unsqueeze(0)\n","                emb = qnet_base(s_t)\n","                # create temporary head to score neighbors by feeding embedding through linear head\n","                # For simplicity we score neighbors by projecting embedding to scalar and select max\n","                # (Consistent with train helper above)\n","                with torch.no_grad():\n","                    tmp_head = nn.Linear(emb.shape[1], 64).to(DEVICE)\n","                    tmp_head2 = nn.Linear(64, 1).to(DEVICE)\n","                    score = tmp_head2(torch.relu(tmp_head(emb))).squeeze().item()\n","                    # note: because head is random initialized, this is roughly random; main training happens via buffer\n","                    # fallback: pick random neighbor\n","                    chosen = random.choice(neighbors)\n","\n","            s2, r, done, info = env.step(chosen)\n","            buffer.add(state, chosen, r, s2, done)\n","            state = s2\n","            ep_reward += r\n","\n","            # train step (simple helper)\n","            _ = train_q_network(qnet_base, None, target_base, optimizer, buffer, BATCH_SIZE)\n","\n","            if done:\n","                break\n","\n","        # update target network periodically\n","        if ep % TARGET_UPDATE_EVERY == 0:\n","            target_base.load_state_dict(qnet_base.state_dict())\n","\n","        # decay epsilon\n","        epsilon = max(EPS_END, epsilon * EPS_DECAY)\n","\n","        if ep % 10 == 0 or ep == 1:\n","            print(f\"Episode {ep:4d}  reward={ep_reward:.2f}  eps={epsilon:.3f} buffer={buffer.size()}\")\n","\n","    # save model\n","    torch.save(qnet_base.state_dict(), \"qnet_base.pth\")\n","    print(\"Training finished. Model saved to qnet_base.pth\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ycdCqNfSz4UG"},"outputs":[],"source":["\n","if __name__ == \"__main__\":\n","    train()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMVA/o/SUKVjLYQI5X457Yt","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}